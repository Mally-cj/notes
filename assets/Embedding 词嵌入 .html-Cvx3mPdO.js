import{_ as a,c as n,a as l,o as r}from"./app-mfcpfX-U.js";const i={};function t(d,e){return r(),n("div",null,e[0]||(e[0]=[l('<h1 id="embedding-词嵌入" tabindex="-1"><a class="header-anchor" href="#embedding-词嵌入"><span>Embedding 词嵌入</span></a></h1><h2 id="前言" tabindex="-1"><a class="header-anchor" href="#前言"><span>前言</span></a></h2><p>2025-04-04 11:41:32 Friday</p><p>参考博客：</p><ul><li><a href="https://blog.csdn.net/v_JULY_v/article/details/102708459" target="_blank" rel="noopener noreferrer">通俗易懂讲解 word2vec</a></li><li><a href="https://blog.csdn.net/weixin_45406155/article/details/120489602" target="_blank" rel="noopener noreferrer">从 NNLM 到 word2vec</a></li><li><a href="https://www.cnblogs.com/jyroy/p/14726894.html" target="_blank" rel="noopener noreferrer">NNLM 详细的代码实现</a></li></ul><h3 id="分词和嵌入的关系" tabindex="-1"><a class="header-anchor" href="#分词和嵌入的关系"><span>分词和嵌入的关系</span></a></h3><ul><li>分词和嵌入是上下游关系： 分词决定如何拆解文本，嵌入决定如何用数字表示拆解后的单元</li><li>现代模型（如 BERT）是端到端的： 分词和嵌入通常被封装在同一个框架中，用户只需输入原始文本</li><li>流程示例：原始文本 → Tokenization → [token_id1, token_id2, ...] → Embedding 查找 → [embedding1, embedding2, ...]</li></ul><h3 id="词嵌入的方法" tabindex="-1"><a class="header-anchor" href="#词嵌入的方法"><span>词嵌入的方法</span></a></h3>',8)]))}const o=a(i,[["render",t]]),h=JSON.parse('{"path":"/AIGC%E7%9B%B8%E5%85%B3/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%95%BF%E6%96%87/Embedding%20%E8%AF%8D%E5%B5%8C%E5%85%A5%20.html","title":"Embedding 词嵌入","lang":"zh-CN","frontmatter":{},"headers":[{"level":2,"title":"前言","slug":"前言","link":"#前言","children":[{"level":3,"title":"分词和嵌入的关系","slug":"分词和嵌入的关系","link":"#分词和嵌入的关系","children":[]},{"level":3,"title":"词嵌入的方法","slug":"词嵌入的方法","link":"#词嵌入的方法","children":[]}]}],"git":{},"filePathRelative":"AIGC相关/大模型长文/Embedding 词嵌入 .md"}');export{o as comp,h as data};
